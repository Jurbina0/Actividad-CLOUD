\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\selectlanguage{spanish}
\usepackage{enumitem,amssymb}
\usepackage{hyperref}
\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\square$}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
 \usepackage{graphicx}
 \usepackage{titling}

 \title{Hacemos un proyecto Big Data
}
\setlength{\headheight}{12.49998pt}
\author{María Correas Crespo, Judith Urbina Córdoba}
\date{\today}
 
 \usepackage{fancyhdr}
\fancypagestyle{plain}{%  the preset of fancyhdr 
    \fancyhf{} % clear all header and footer fields
    \fancyfoot[R]{\includegraphics[width=2cm]{uoc_masterbrand_2linies_posititiu.jpg}}
    \fancyfoot[L]{\thedate}
    \fancyhead[L]{Implementación AWS}
    \fancyhead[R]{\theauthor}
}
\makeatletter
\def\@maketitle{%
  \newpage
  \null
  \vskip 1em%
  \begin{center}%
  \let \footnote \thanks
    {\LARGE \@title \par}%
    \vskip 1em%
    %{\large \@date}%
  \end{center}%
  \par
  \vskip 1em}
\makeatother

\usepackage{lipsum}  
\usepackage{cmbright}

\begin{document}

\maketitle

\noindent\begin{tabular}{@{}ll}
    Estudiantes & \theauthor\\
     Profesor &  Marta Martín Moreno\\
     Asignatura & Análisis de Datos en entornos Big Data
\end{tabular}
\section{Actividad: Definición Objetivos y KPIs}
\subsection*{Descripción}
En esta actividad, se propone que desarrolléis un pequeño proyecto de Big data utilizando las herramientas de esta plataforma. El proyecto se dividirá en dos entregas que cubrirán la definición de objetivos y KPIs y la implementación de la propuesta mediante herramientas de AWS. Finalmente, presentaréis vuestra propuesta de proyecto a vuestros compañeros del aula. La temática es libre; podéis elegir una área de interés o aplicar el aprendizaje a un problema real próximo a vosotros.

En esta primera fase del proyecto, tenéis que definir el alcance del proyecto, establecer objetivos claros y medibles, e identificar los KPI (Key Performance Indicators) que usaréis para evaluar el éxito del proyecto. 
\subsection*{Objetivos}
Se pide:
\begin{enumerate}
    \item Selección de la temática o caso de estudio
    \begin{todolist}
         \item área de interés o un caso de estudio que queráis abordar con el proyecto de Big data
         \item temática tiene que ser relevante y aplicable a un contexto real.
    \end{todolist}
    \item Descripción del problema
    \begin{todolist}
         \item Aseguraos de describir por qué este problema es importante
         \item  qué impacto puede tener su resolución
    \end{todolist}
    \item Establecimiento de objetivos. Los objetivos tienen que ser realistas y alineados con la resolución del problema identificado.
    \begin{todolist}
         \item Definís objetivos específicos y medibles que queréis lograr con el proyecto.
         \item Explicad cómo el análisis de datos contribuirá a conseguir estos objetivos.
    \end{todolist}
    \item Definición de KPI.
    \begin{todolist}
         \item Definís tres KPI (Key Performance Indicators) que sean relevantes para mesurar el éxito del proyecto
         \item Explicad por qué estos KPI son importantes
         \item cómo se relacionan con los objetivos establecidos, y de qué manera se mesurarán.
    \end{todolist}
    \item Identificación de fuentes de datos.
    \begin{todolist}
         \item  Identifica y describe las fuentes de datos que has utilizado para abordar el problema.
         \item  Indicáis la naturaleza de los datos,
         \item su procedencia
         \item  cómo se prevé que sean utilizadas en el análisis.
    \end{todolist}
    \item Asignación de tareas dentro del equipo.
    \begin{todolist}
         \item Repartís las responsabilidades y tareas entre los miembros del equipo.
         \item Aseguraos que cada miembro tiene un papel claro y definido,
         \item tareas asignadas son coherentes con sus habilidades y roles dentro del proyecto.
    \end{todolist}
\end{enumerate}
\subsection*{Propuestas de datasets}
Datos de buena calidad para minimizar la corrección.
Datos que tengan información relevante, precisa y actualizada.
Algunos enlaces que podrían ser útiles
\begin{enumerate}
    \item Ofrecido por Amazon y con ejemplos \href{https://registry.opendata.aws/}{Open data on AWS}
    \item estados unidos \href{https://catalog.data.gov/dataset?q=&sort=views_recent+desc}{catálogo de datagov}
    \item europa \href{https://data.europa.eu/data/datasets?locale=en}{data europa}
    \item Plataformas de código abierto creando cuenta: \href{https://www.pewresearch.org/datasets/}{pewresearch}
    \item Contiene un listado mayor de datasets \href{https://oad.simmons.edu/oadwiki/Data_repositories}{Open Access Directory}
    \item Otro listado mayor de datasets \href{https://libraryguides.missouri.edu/datasets/public-use}{Universidad de Missouri}
    \item Si se sabe buscar datasets amplios \href{https://datasetsearch.research.google.com/}{Dat search}
    \item Muy bien documentada la manera de citar y otros detalles \href{https://www.nature.com/sdata/policies/repositories}{nature}
    \item Contiene lista de centros de datasets y tips para elegir \href{https://sqream.com/blog/big-datasets-for-analysis/#:~:text=We%E2%80%99ll%20guide%20you%20through%20key%20factors%20to%20consider%2C,would%20be%20impossible%20to%20detect%20in%20smaller%20datasets.}{sqream}
    
\end{enumerate}
No se puede abrir al entrar dentro del dataset o hay pegas
\begin{enumerate}
    \item Migraciones de animales! \href{https://www.movebank.org/cms/webapp?gwt_fragment=page=search_map}{movebank}
    \item varios \href{https://www.re3data.org/}{re3data}
\end{enumerate}
\section{Actividad: Implementación AWS}
\subsection*{Descripción}
En el proyecto Big Data tenemos que tener
\begin{enumerate}
    \item Pruebas de proceso de datos.
    \begin{todolist}
        \item  Realizáis un conjunto de pruebas para aseguraros que los datos se están procesando correctamente.
        \item Describís los pasos seguidos para verificar la precisión y la consistencia del proceso de datos.
    \end{todolist}
    \item Validación de los KPIs.
    \begin{todolist}
        \item Validáis que los KPIs definidos están correctamente medidos y que reflejan fielmente la realidad del análisis.
        \item Explicáis los métodos utilizados para asegurar la precisión y la relevancia de los KPIs.
    \end{todolist}
    \item Incorporación de scripts o código relevante.
    \begin{todolist}
        \item  Incluis los scripts o código más relevantes que han sido utilizados durante la implementación del proyecto.
        \item Aseguraos que están suficientemente descritos para facilitar la comprensión de las operaciones realizadas.
    \end{todolist}
\end{enumerate}

\subsection*{Objetivos}
Por servicio de AWS usado
\begin{enumerate}
    \item Por qu:e hemos usado este servicio? C:omo se relaciona con nuestros objetivos de proyecto?
    \item C:omo lo describimos?
    \item C:omo lo hemos usado? Con qu:e tipo de datos hemos trabajado en nuestro proyecto?
\end{enumerate}
En detalle describimos
\begin{enumerate}
    \item con un diagrama de \href{https://aws.amazon.com/es/architecture/icons/}{Amazon diagramas}
    \item c:omo realizaremos el procesamientode los datos a AWS?
    \begin{todolist}
        \item explicación de los flujos de trabajo
        \item explicación de las transformaciones de datos
        \item gestión de la integración entre los diferentes servicios de AWS
    \end{todolist}
\end{enumerate}
Usamos 



\subsection*{Recomendaciones}
\lipsum[4-4]
Maximizar el uso de los servicios PaaS:
\begin{enumerate}
    \item servicios S3, Lambda, Kinesis, EMR, EC2, Glue, Athena o Redshift
\end{enumerate}
y minimizar el uso de servicios IaaS

\newpage 
\section{Jupyter Notebook: Actividad Cloud con AWS}
\subsection{Ejercicio 1: Descripción y justificación de los servicios de AWS (2,5 pts)}

El proyecto tiene como objetivo manejar datos inmobiliarios de Londres almacenados en un archivo CSV, procesarlos e integrarlos en una base de datos para consultas posteriores a través de funciones Lambda. A continuación, describimos los servicios seleccionados y su justificación:

\subsubsection{Amazon S3 (Simple Storage Service)}
\textbf{Justificación:}
Amazon S3 es ideal para almacenar grandes cantidades de datos estructurados o no estructurados de manera económica y escalable. En este caso, se utiliza para almacenar el archivo CSV inicial con los datos de las casas.\\
\textbf{Rol en el flujo:}
Almacena el archivo datos.csv con los datos de propiedades inmobiliarias.
Actúa como origen de datos para AWS Glue.

\subsubsection{Amazon RDS (Relational Database Service)}
\textbf{Justificación:}
Amazon RDS ofrece una base de datos gestionada que es confiable, escalable y fácil de usar. Es perfecta para alojar los datos transformados y permitir consultas rápidas y eficientes. En este caso, se elige MySQL como motor de base de datos debido al amplio soporte de la comunidad, la buena integración con AWS Lambda y herramientas de análisis de datos y la capacidad de manejar datos estructurados como los requeridos en este proyecto.\\
\textbf{Rol en el flujo:}
Almacena los datos inmobiliarios procesados de forma relacional.
Sirve como origen para las consultas realizadas por las funciones Lambda.


\subsubsection{AWS Lambda}
\textbf{Justificación:}
AWS Lambda permite ejecutar código en respuesta a eventos y es ideal para construir aplicaciones backend sin servidor. Es eficiente en costos y escalable.\\
\textbf{Rol en el flujo:}
Una Lambda consulta la base de datos para buscar casas según filtros específicos (por ejemplo, precio, número de habitaciones, ubicación).
Otra Lambda permite gestionar casas favoritas por usuario y realiza actualizaciones en la base de datos.

\subsubsection{Amazon API Gateway}
\textbf{Justificación:}
API Gateway actúa como puerta de enlace para exponer las funciones Lambda como endpoints HTTP, permitiendo que los usuarios interactúen con el backend.\\
\textbf{Rol en el flujo:}
Proporciona endpoints RESTful para las funcionalidades: búsqueda de casas, gestión de usuarios, casas favoritas, etc.
Maneja la autenticación y autorización para garantizar la seguridad.



\subsubsection{Amazon Secrets Manager}
\textbf{Justificación:}
AWS Secrets Manager es un servicio diseñado para almacenar y gestionar de forma segura secretos como credenciales de bases de datos, claves API y otros datos confidenciales. En este proyecto, se utiliza para almacenar y gestionar las credenciales de acceso a la base de datos MySQL en Amazon RDS. Esto evita la necesidad de incluir credenciales en el código fuente de las funciones Lambda, mejorando la seguridad y facilitando la rotación de credenciales. \\

\textbf{Rol en el flujo:}
Se crea un secreto en Secrets Manager que almacena las credenciales de la base de datos (nombre de usuario, contraseña, endpoint, y puerto).
Las funciones Lambda solicitan el secreto durante su ejecución mediante la API de Secrets Manager (GetSecretValue).
Las credenciales se utilizan para establecer la conexión con MySQL en RDS.


\subsubsection{AWS Identity and Access Management (IAM)}
\textbf{Justificación:}
AWS IAM proporciona control de acceso granular a los recursos y servicios de AWS. En este proyecto, IAM se utiliza para asignar los permisos mínimos necesarios a cada recurso, asegurando la seguridad del flujo de trabajo.

\textbf{Rol en el flujo:}

Roles para Lambda:
Se crea un rol IAM asociado a las funciones Lambda con permisos específicos para:
Acceder a Secrets Manager (secretsmanager:GetSecretValue).
Registrar logs en CloudWatch.
Este enfoque de permisos mínimos garantiza que las Lambdas solo tengan acceso a los recursos que necesitan.
Permisos de Glue:
Glue tiene permisos para acceder al bucket S3 donde se encuentra el archivo CSV y para cargar los datos transformados en RDS.
Políticas específicas:
Cada servicio (S3, RDS, Secrets Manager) tiene políticas asignadas de manera individual para minimizar riesgos.



\subsubsection{Amazon Virtual Private Cloud (VPC)}
\textbf{Justificación:}
Amazon VPC proporciona una red privada y aislada dentro de la nube de AWS, lo que garantiza un entorno seguro para servicios como RDS. En este proyecto, la VPC se utiliza para proteger la base de datos y limitar el acceso desde Internet.

\textbf{Rol en el flujo:}

Base de datos RDS:
La base de datos MySQL se encuentra dentro de una subred privada de la VPC. Esto asegura que solo los recursos autorizados dentro de la VPC (como Lambda) puedan acceder a ella.
Funciones Lambda:
Las funciones Lambda están configuradas para ejecutar dentro de la misma VPC, con acceso a subredes privadas que les permitan comunicarse con RDS.
Configuración de seguridad:
Los grupos de seguridad de la VPC permiten únicamente el tráfico necesario (por ejemplo, conexiones entrantes desde Lambda a RDS en el puerto 3306).
Opcional: Endpoints de VPC:
Para mejorar la seguridad y reducir la latencia, se podrían configurar endpoints de VPC para que servicios como S3 y Secrets Manager sean accesibles directamente desde la VPC, sin pasar por Internet.



\subsubsection{Flujo de trabajo}
A continuación, se describe el flujo de trabajo, incluyendo las transformaciones de datos y la integración entre servicios:

\paragraph{Ingesta de datos desde Amazon S3} \mbox{} \\
El archivo \texttt{houses.csv} es subido al bucket de Amazon S3.  
AWS Glue utiliza un \textit{crawler} para explorar el esquema del archivo CSV y generar una tabla en el Data Catalog.  
Un \textit{job} ETL en AWS Glue procesa los datos realizando las siguientes transformaciones:
\begin{itemize}
    \item Eliminación de duplicados y filas incompletas.
    \item Conversión de formatos de campos (por ejemplo, fechas y precios).
    \item Agregación de datos calculados, como el precio por metro cuadrado.
\end{itemize}

\paragraph{Almacenamiento de datos en Amazon RDS (MySQL)} \mbox{} \\
Los datos transformados se cargan en una tabla de la base de datos MySQL gestionada en Amazon RDS.  
Se configuran relaciones entre tablas, como las que vinculan propiedades y usuarios.

\paragraph{Gestión segura de credenciales con AWS Secrets Manager} \mbox{} \\
Las credenciales de la base de datos MySQL (nombre de usuario, contraseña, endpoint y puerto) se almacenan de forma segura en AWS Secrets Manager.  
Las funciones Lambda acceden a estos secretos en tiempo de ejecución mediante la API de Secrets Manager, eliminando la necesidad de incluir credenciales en el código fuente.

\paragraph{Exposición de funcionalidades mediante AWS Lambda y API Gateway} \mbox{} \\
Las funciones AWS Lambda interactúan con la base de datos MySQL en RDS:
\begin{itemize}
    \item Una función Lambda ejecuta consultas \texttt{SELECT} para devolver resultados basados en filtros proporcionados por los usuarios, como precio, ubicación o número de habitaciones.
    \item Otra función Lambda realiza operaciones de escritura, como gestionar las casas favoritas de cada usuario (por ejemplo, \texttt{INSERT} y \texttt{UPDATE}).
\end{itemize}
AWS API Gateway expone estas funciones Lambda como \textit{endpoints} HTTP para su uso desde el frontend de la aplicación.

\paragraph{Gestión de accesos con AWS IAM} \mbox{} \\
Se definen roles y políticas en AWS Identity and Access Management (IAM) para garantizar que cada servicio tenga acceso únicamente a los recursos necesarios:
\begin{itemize}
    \item Las funciones Lambda tienen un rol con permisos para acceder a Secrets Manager, CloudWatch Logs y RDS.
    \item AWS Glue tiene un rol con permisos para leer el bucket S3 y escribir datos en RDS.
\end{itemize}

\paragraph{Seguridad y conectividad mediante Amazon VPC} \mbox{} \\
Amazon Virtual Private Cloud (VPC) asegura la comunicación entre los servicios de forma privada:
\begin{itemize}
    \item La base de datos MySQL en Amazon RDS está alojada en una subred privada dentro de la VPC.
    \item Las funciones Lambda están configuradas para ejecutarse dentro de la misma VPC, permitiendo acceso seguro a la base de datos.
    \item Los \textit{security groups} controlan el tráfico permitido entre Lambda y RDS, asegurando que solo las conexiones necesarias sean aceptadas.
\end{itemize}
Opcionalmente, se pueden configurar \textit{endpoints} de VPC para que servicios como S3 o Secrets Manager sean accesibles sin salir de la red privada.


\subsubsection{Políticas y roles de IAM}

\paragraph{AWS Glue} \mbox{} \\
Se muerstra la política de IAM en formato JSON que se ha asociado para permitir a AWS Glue acceder al bucket S3, la base de datos RDS, ejecutar Glue Jobs y escribir logs en CloudWatch:

\begin{verbatim}
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::<nombre-del-bucket-s3>",
        "arn:aws:s3:::<nombre-del-bucket-s3>/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "rds:DescribeDBInstances",
        "rds:Connect"
      ],
      "Resource": "arn:aws:rds:<region>:<account-id>:db:<nombre-de-la-base-de-datos>"
    },
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "arn:aws:logs:<region>:<account-id>:log-group:/aws/glue/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "glue:CreateJob",
        "glue:DeleteJob",
        "glue:UpdateJob",
        "glue:StartJobRun",
        "glue:GetJob",
        "glue:GetJobRun",
        "glue:GetTable",
        "glue:GetTables",
        "glue:BatchCreatePartition",
        "glue:BatchDeletePartition",
        "glue:GetPartition",
        "glue:GetPartitions",
        "glue:UpdateTable"
      ],
      "Resource": "*"
    }
  ]
}
\end{verbatim}
Explicación de cada sección:
Acceso a S3:

Se otorgan permisos de lectura (s3:GetObject) y de listado de objetos (s3:ListBucket) sobre el bucket S3 específico. Reemplaza <nombre-del-bucket-s3> con el nombre de tu bucket.
Acceso a RDS:

Se otorgan permisos para describir las instancias de RDS (rds:DescribeDBInstances) y conectar a la base de datos (rds:Connect). Reemplaza <nombre-de-la-base-de-datos> con el nombre de tu base de datos y ajusta la región y el ID de cuenta de AWS.
Permisos para CloudWatch Logs:

Se permiten acciones necesarias para crear log groups, crear log streams y escribir eventos de log en CloudWatch (logs:CreateLogGroup, logs:CreateLogStream, logs:PutLogEvents). Esto es útil para que los Glue Jobs generen logs.
Permisos de Glue:

Se permiten varias acciones de Glue, como crear, actualizar, ejecutar y obtener detalles de los Glue Jobs, así como trabajar con las tablas y particiones en el Glue Data Catalog.



\paragraph{AWS Lambda} \mbox{} \\

Se muestra la política de IAM en formato JSON para permitir que una función Lambda interactúe con RDS, Secrets Manager, CloudWatch Logs y API Gateway.
\begin{verbatim}
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "rds:DescribeDBInstances",
        "rds:Connect",
        "rds:ExecuteStatement"
      ],
      "Resource": "arn:aws:rds:<region>:<account-id>:db:<nombre-de-la-base-de-datos>"
    },
    {
      "Effect": "Allow",
      "Action": [
        "secretsmanager:GetSecretValue"
      ],
      "Resource": "arn:aws:secretsmanager:<region>:<account-id>:secret:<nombre-del-secret>/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "arn:aws:logs:<region>:<account-id>:log-group:/aws/lambda/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "apigateway:GET",
        "apigateway:POST",
        "apigateway:PUT",
        "apigateway:DELETE"
      ],
      "Resource": "arn:aws:apigateway:<region>::/restapis/*"
    }
  ]
}
\end{verbatim}
Explicación de la política:
Acceso a RDS:

Permisos para interactuar con RDS: Se otorgan permisos de descripción (rds:DescribeDBInstances), conexión (rds:Connect) y ejecución de sentencias SQL (rds:ExecuteStatement) para interactuar con la base de datos. Asegúrate de reemplazar <nombre-de-la-base-de-datos> con el nombre de tu base de datos y ajustar la región y el ID de cuenta.
Acceso a Secrets Manager:

Permisos para acceder a los secretos: Se otorgan permisos de lectura (secretsmanager:GetSecretValue) para recuperar el valor de los secretos almacenados en AWS Secrets Manager. Reemplaza <nombre-del-secret> con el nombre del secret que contiene las credenciales para acceder a tu base de datos.
Acceso a CloudWatch Logs:

Permisos para CloudWatch Logs: Se permiten las acciones necesarias para crear un log group, crear un log stream y escribir eventos de log en CloudWatch. Estos permisos son necesarios para que la función Lambda registre las métricas de ejecución. Se usa la ruta /aws/lambda/* para indicar que se aplica a todas las funciones Lambda en la cuenta.
Acceso a API Gateway:

Permisos para interactuar con API Gateway: Se permiten las acciones para hacer peticiones HTTP (GET, POST, PUT, DELETE) a cualquier API de API Gateway en la región. Esto es útil si la Lambda va a realizar alguna operación relacionada con una API Gateway (por ejemplo, invocar API Gateway o interactuar con recursos de una API).


\newpage
\subsection{Ejercicio 2: Pruebas de procesamiento de datos (2,5 puntos)}
\subsubsection{Pruebas de procesamiento de datos}

El objetivo de estas pruebas es asegurar que los datos se procesan de forma correcta y consistente desde su ingesta hasta su almacenamiento final. A continuación, se describe el conjunto de pruebas diseñadas para validar cada etapa del flujo de trabajo.

\paragraph{Preparación de los datos de prueba} \mbox{} \\
\begin{itemize}
    \item \textbf{Generación de datos de prueba:} Se crea un archivo CSV sintético (\texttt{houses\_test.csv}) con un subconjunto de datos representativos que incluye:
    \begin{itemize}
        \item Datos correctos.
        \item Datos duplicados.
        \item Filas incompletas.
        \item Valores atípicos (outliers).
    \end{itemize}
    \item \textbf{Carga en S3:} El archivo se sube manualmente al bucket de Amazon S3 utilizado por el proyecto.
\end{itemize}

\paragraph{Validación del proceso ETL en AWS Glue} \mbox{} \\
\begin{itemize}
    \item \textbf{Ejecución del ETL:} Se ejecuta el \textit{job} de Glue sobre el archivo de prueba en S3.
    \item \textbf{Pruebas de transformación:} Los datos transformados se exportan en formato Parquet o CSV a un bucket de S3 intermedio para su validación:
    \begin{itemize}
        \item Confirmación de la eliminación de duplicados.
        \item Validación de la eliminación de filas incompletas.
        \item Verificación de las transformaciones aplicadas a columnas (formato de fechas, normalización de precios, etc.).
        \item Cálculo correcto de campos derivados, como el precio por metro cuadrado.
    \end{itemize}
\end{itemize}

\paragraph{Pruebas de almacenamiento en Amazon RDS (MySQL)} \mbox{} \\
\begin{itemize}
    \item \textbf{Carga de datos en RDS:} Los datos transformados son cargados en una base de datos MySQL en Amazon RDS.
    \item \textbf{Consultas de validación:} Desde una instancia EC2, se realizan las siguientes verificaciones:
    \begin{itemize}
        \item Comprobación de la cantidad de filas cargadas.
        \item Validación de las relaciones entre tablas (por ejemplo, propiedades asociadas a usuarios).
        \item Verificación de la integridad de los datos (sin duplicados, sin filas incompletas).
    \end{itemize}
\end{itemize}

\paragraph{Pruebas de consulta mediante AWS Lambda} \mbox{} \\
\begin{itemize}
    \item \textbf{Pruebas de consulta:} Se invocan directamente las funciones Lambda que consultan la base de datos:
    \begin{itemize}
        \item Verificación de que los filtros de búsqueda (precio, ubicación, número de habitaciones) devuelven resultados precisos.
        \item Comprobación de la funcionalidad de gestión de favoritos (inserción y eliminación de registros).
    \end{itemize}
    \item \textbf{Exposición de APIs:} Se validan los \textit{endpoints} HTTP expuestos por API Gateway para asegurar que devuelven respuestas coherentes.
\end{itemize}

\paragraph{Monitoreo en CloudWatch Logs:} \mbox{} \\
Se revisan los logs generados por las funciones Lambda y AWS Glue para identificar posibles errores o advertencias.

\paragraph{Validación adicional con Amazon Athena} \mbox{} \\
Se configura Amazon Athena para realizar consultas SQL directamente sobre los datos procesados almacenados en S3:
\begin{itemize}
    \item Validación de la calidad de los datos intermedios antes de su carga en RDS.
    \item Comparación de los resultados en S3 con los datos finales en MySQL.
\end{itemize}

\paragraph{Resumen del flujo y herramientas utilizadas} \mbox{} \\
\begin{table}[h!]
    \centering
    \begin{tabular}{|l|l|p{8cm}|}
        \hline
        \textbf{Etapa del flujo} & \textbf{Servicio utilizado} & \textbf{Validación realizada} \\ \hline
        Ingesta de datos         & Amazon S3                  & Archivo CSV cargado correctamente. \\ \hline
        ETL                     & AWS Glue                   & Transformaciones y formato validados. \\ \hline
        Almacenamiento          & Amazon RDS (MySQL)         & Integridad y relaciones de datos verificadas. \\ \hline
        Consultas               & AWS Lambda + API Gateway   & Respuestas correctas a las consultas HTTP. \\ \hline
        Consulta avanzada       & Amazon Athena              & Validación de datos intermedios en S3. \\ \hline
        Monitoreo               & CloudWatch Logs            & Identificación y resolución de errores. \\ \hline
    \end{tabular}
    \caption{Flujo de validación y servicios utilizados.}
\end{table}


\subsubsection{Ejercicio 3: Validación de los KPIs}

Para asegurar que los KPIs (Key Performance Indicators) definidos están correctamente medidos y reflejan fielmente la realidad del análisis, se deben seguir los pasos y métodos descritos a continuación para validar la precisión y la relevancia de los KPIs en la versión de prueba.

\paragraph{1. Definición Clara y Precisa de los KPIs} \mbox{} \\
En la fase de pruebas, los KPIs deben estar alineados con los objetivos específicos del proyecto. Algunos KPIs relevantes en esta fase de test son los siguientes:

\begin{itemize}
    \item \textbf{Tiempo de procesamiento de datos (ETL):} El tiempo que toma procesar el archivo CSV a través del job de Glue.
    \item \textbf{Precisión de los datos cargados en RDS:} Porcentaje de datos correctos tras el procesamiento y carga en la base de datos.
    \item \textbf{Tiempo de respuesta de las funciones Lambda:} Tiempo medio de respuesta de las funciones Lambda al realizar consultas a la base de datos.
    \item \textbf{Consistencia de los datos en las funciones Lambda:} Porcentaje de consultas de Lambda que devuelven resultados correctos sin errores.
    \item \textbf{Disponibilidad del sistema (Uptime):} Porcentaje de tiempo en que los servicios (Lambda, RDS, Glue, etc.) están operativos durante las pruebas.
\end{itemize}

Cada KPI es fácilmente medible y cuantificable, utilizando unidades de medida estándar y asegurando que los datos se recopilan de manera coherente.

\paragraph{2. Recopilación de Datos Consistente} \mbox{} \\
Los datos necesarios para medir estos KPIs deben ser obtenidos de manera consistente. Las fuentes de datos relevantes incluyen:

\begin{itemize}
    \item \textbf{Logs de AWS Lambda:} Para medir el tiempo de respuesta de las funciones Lambda y verificar que las consultas se ejecutan correctamente.
    \item \textbf{CloudWatch:} Para analizar el rendimiento de Glue y Lambda.
    \item \textbf{Consultas en MySQL (RDS):} Para verificar la precisión de los datos cargados y las relaciones entre tablas.
    \item \textbf{AWS Glue y RDS Metrics:} Para medir el tiempo de procesamiento de los datos, la eficiencia del ETL y la carga en RDS.
\end{itemize}

Los datos se recopilan utilizando **CloudWatch** para las métricas y logs, y consultas en **MySQL** para las validaciones de precisión de datos.

\paragraph{3. Validación de la Precisión} \mbox{} \\
Para garantizar que los datos y resultados de las pruebas sean precisos, se deben realizar las siguientes acciones:

\begin{itemize}
    \item \textbf{Auditoría de Logs:} Revisión periódica de los logs generados por Lambda y Glue en **CloudWatch** para asegurar que no haya errores en el procesamiento de datos ni en las consultas de Lambda.
    \item \textbf{Comparación de Resultados:} Verificación de que los resultados obtenidos de las funciones Lambda y las consultas en MySQL sean correctos. Esto incluye la validación de los datos cargados en RDS comparándolos con los datos del archivo CSV original.
    \item \textbf{Comprobación de Cálculos:} Validación de cálculos derivados, como el precio por metro cuadrado, para asegurar que se realicen correctamente en el ETL.
\end{itemize}

Durante la fase de pruebas, se puede realizar una auditoría manual comparando los resultados esperados con los obtenidos de las consultas en Lambda y MySQL.

\paragraph{4. Análisis de la Relevancia} \mbox{} \\
Para garantizar que los KPIs sean relevantes, se deben realizar las siguientes acciones:

\begin{itemize}
    \item \textbf{Análisis de Correlación:} Realización de análisis estadísticos para determinar si los KPIs están correlacionados con los resultados deseados. Por ejemplo, se puede analizar si el tiempo de respuesta de Lambda está correlacionado con la cantidad de datos procesados en Glue.
    \item \textbf{Feedback Continuo:} Recopilación de retroalimentación de los stakeholders para asegurar que los KPIs sean relevantes y reflejen las preocupaciones de los usuarios del sistema.
\end{itemize}

El análisis de correlación puede incluir estudios estadísticos para validar la efectividad de los KPIs, como la relación entre el volumen de datos procesados y el tiempo de respuesta de las funciones Lambda.

\paragraph{5. Revisión y Ajuste Continuos} \mbox{} \\
Dado que este es un proyecto en fase de pruebas, es fundamental revisar y ajustar los KPIs a medida que se identifican posibles problemas de rendimiento. Las actividades a realizar incluyen:

\begin{itemize}
    \item \textbf{Revisión de los KPIs:} Revisión periódica de los KPIs, analizando los logs y métricas para identificar desviaciones o caídas en el rendimiento.
    \item \textbf{Ajustes en los KPIs:} Si se detectan problemas, como tiempos de respuesta lentos o procesamiento ineficiente, los KPIs pueden ajustarse para reflejar mejor el rendimiento del sistema en pruebas.
\end{itemize}

La revisión de los KPIs debe ser continua, ajustando las métricas según se necesite para reflejar el rendimiento real del sistema.

\paragraph{6. Documentación de los Métodos Utilizados} \mbox{} \\
Es fundamental documentar el proceso de medición y validación de los KPIs, detallando los métodos utilizados:

\begin{itemize}
    \item \textbf{Métodos de Recopilación de Datos:} Descripción de cómo se recopilan los datos de los KPIs a través de logs de CloudWatch, consultas MySQL y métricas de AWS.
    \item \textbf{Auditorías Realizadas:} Detalles de las auditorías periódicas realizadas para verificar la precisión y consistencia de los datos.
    \item \textbf{Análisis Estadístico:} Documentación del análisis de correlación para validar la relevancia de los KPIs.
    \item \textbf{Transparencia:} Mantener total transparencia en el proceso para que los stakeholders tengan confianza en los KPIs definidos.
\end{itemize}

\paragraph{KPIs a Medir en la Versión de Test}

A continuación se muestran los KPIs que se medirán en la versión de pruebas del proyecto:

\begin{table}[h!]
    \centering
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|l|l|p{8cm}|}
        \hline
        \textbf{KPI}                         & \textbf{Descripción}                                                 & \textbf{Método de Medición}                          \\ \hline
        Tiempo de procesamiento ETL          & Tiempo para procesar el archivo CSV a través de AWS Glue.            & Medición de logs de Glue y métricas de CloudWatch. \\ \hline
        Precisión de los datos cargados en RDS & Porcentaje de datos correctos tras la carga en RDS.                   & Comparación de datos entre el archivo CSV y RDS.    \\ \hline
        Tiempo de respuesta Lambda           & Promedio de tiempo de respuesta de las funciones Lambda.             & Logs de CloudWatch de Lambda.                      \\ \hline
        Consistencia de los datos en Lambda  & Porcentaje de consultas Lambda que devuelven resultados correctos.   & Comparación de resultados de consultas con los esperados. \\ \hline
        Disponibilidad del sistema (Uptime)  & Porcentaje de tiempo que los servicios están operativos.             & Métricas de CloudWatch para Glue, Lambda y RDS.    \\ \hline
    \end{tabular}
    }
    \caption{KPIs a medir en la versión de test del proyecto.}
\end{table}


Esta estructura asegura que se cubren todos los aspectos relevantes de los KPIs durante la fase de prueba y permite medir de manera precisa el rendimiento del sistema en este entorno.

\end{document}
